{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff7a90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor as Xgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#SKforecast\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from skforecast.datasets import fetch_dataset\n",
    "from skforecast.preprocessing import RollingFeatures\n",
    "from skforecast.recursive import ForecasterRecursiveMultiSeries\n",
    "from skforecast.model_selection import (\n",
    "    TimeSeriesFold,\n",
    "    backtesting_forecaster_multiseries,\n",
    "    grid_search_forecaster_multiseries,\n",
    "    bayesian_search_forecaster_multiseries,\n",
    ")\n",
    "\n",
    "from skforecast.plot import set_dark_theme\n",
    "from skforecast.feature_selection import select_features_multiseries\n",
    "\n",
    "#SKLEARN\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "#MLFLOW\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "import pickle\n",
    "\n",
    "#Exogenous variables \n",
    "import holidays\n",
    "from vacances_scolaires_france import SchoolHolidayDates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e620c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vacances scolaires\n",
    "d = SchoolHolidayDates()\n",
    "dates_vacances=set()\n",
    "for y in (2023,2024):\n",
    "    vacances=d.holidays_for_year_and_zone(y, 'C')\n",
    "    dates_vacances.update(vacances.keys())\n",
    "\n",
    "#jours feri√©s\n",
    "feries = holidays.France(years=['2023','2024'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcb3364",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"lit_cluster_1.csv\",index_col=\"date_semaine\", parse_dates=True)\n",
    "data=data.asfreq('W') \n",
    "list_uf =data.columns.tolist()\n",
    "\n",
    "data['vacances']= data.index.isin(dates_vacances).astype(int)\n",
    "data['feries'] = data.index.isin(feries).astype(int)\n",
    "data[\"month\"] = data.index.month\n",
    "data[\"week_of_year\"] = data.index.isocalendar().week\n",
    "\n",
    "exog_list=data.columns.drop(list_uf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d308fcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = len(data)\n",
    "train_size = int(0.6 * n_samples)  \n",
    "val_size = int(0.2 * n_samples)  \n",
    "\n",
    "data_train = data.iloc[:train_size]\n",
    "data_val = data.iloc[train_size:train_size + val_size]\n",
    "data_test = data.iloc[train_size + val_size:]\n",
    "\n",
    "print(f\"Total samples: {n_samples}\")\n",
    "print(f\"Train: {len(data_train)} samples : {data_train.index[0]} to {data_train.index[-1]}\")\n",
    "print(f\"Validation: {len(data_val)} samples : {data_val.index[0]} to {data_val.index[-1]}\")\n",
    "print(f\"Test: {len(data_test)} samples : {data_test.index[0]} to {data_test.index[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdff8513",
   "metadata": {},
   "outputs": [],
   "source": [
    "col=\"2456\"\n",
    "set_dark_theme()\n",
    "plt.figure(figsize=(12, 4))\n",
    " \n",
    "data_train[col].plot( label='train')\n",
    "data_val[col].plot( label='validation')\n",
    "data_test[col].plot( label='test')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6985890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train ForecasterRecursiveMultiSeries\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterRecursiveMultiSeries(\n",
    "                 regressor          = RandomForestRegressor(n_estimators=100,random_state=42),\n",
    "                 lags               = 52,\n",
    "                 window_features    = RollingFeatures(stats=['mean', 'mean','mean','std','std','std'], window_sizes=[4, 24, 52, 4, 24, 52]),\n",
    "                 encoding           = 'ordinal'\n",
    "             )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38ae109",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = TimeSeriesFold(\n",
    "        steps                 = 21,\n",
    "        initial_train_size    = len(data_train),\n",
    "        refit                 = False,\n",
    "        fixed_train_size      = False,\n",
    "        gap                   = 0,\n",
    "        allow_incomplete_fold = True\n",
    "     )\n",
    "\n",
    "metrics_levels, backtest_predictions = backtesting_forecaster_multiseries(\n",
    "    forecaster            = forecaster,\n",
    "    series                = data.iloc[:train_size+val_size][list_uf],\n",
    "    exog                  = data.iloc[:train_size+val_size][exog_list],\n",
    "    cv                    = cv,\n",
    "    levels                = None,\n",
    "    metric                = 'mean_absolute_error',\n",
    "    add_aggregated_metric = True\n",
    ")\n",
    "\n",
    "print(\"Backtest metrics\")\n",
    "display(metrics_levels)\n",
    "print(\"\")\n",
    "print(\"Backtest predictions\")\n",
    "backtest_predictions.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e102ca36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tscv = TimeSeriesSplit(n_splits=3)\n",
    "regressor = LGBMRegressor(n_estimators=100, max_depth=5, random_state=15926, verbose=-1)\n",
    "selector = RFECV(estimator=regressor, step=1, cv=tscv, min_features_to_select=1,scoring='neg_mean_absolute_error')\n",
    "selected_lags, selected_window_features, selected_exog = select_features_multiseries(\n",
    "    forecaster      = forecaster,\n",
    "    selector        = selector,\n",
    "    series          = data.iloc[:train_size+val_size][list_uf],\n",
    "    exog            = data.iloc[:train_size+val_size][exog_list],\n",
    "    select_only     = None,\n",
    "    force_inclusion = None,\n",
    "    subsample       = 0.5,\n",
    "    random_state    = 123,\n",
    "    verbose         = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b97861c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats=[]\n",
    "window_sizes=[]\n",
    "for i, value in enumerate(selected_window_features):\n",
    "    stats.append(selected_window_features[i].split(\"_\")[1])\n",
    "    window_sizes.append(int(selected_window_features[i].split(\"_\")[2]))\n",
    "\n",
    "forecaster.set_lags(lags=selected_lags)\n",
    "forecaster.set_window_features(window_features=RollingFeatures(stats=stats, window_sizes=window_sizes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b41b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "levels = list_uf\n",
    "\n",
    "# Search space\n",
    "def search_space(trial):\n",
    "    search_space = {\n",
    "        # Core Random Forest parameters\n",
    "        'n_estimators'      : trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'max_depth'         : trial.suggest_int('max_depth', 3, 20),\n",
    "        'min_samples_split' : trial.suggest_int('min_samples_split', 2, 20),\n",
    "        'min_samples_leaf'  : trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "        \n",
    "        # Feature selection parameters\n",
    "        'max_features'      : trial.suggest_categorical('max_features', ['sqrt', 'log2', None]),\n",
    "        'max_samples'       : trial.suggest_float('max_samples', 0.5, 1.0),\n",
    "        \n",
    "        # Tree building parameters\n",
    "        'bootstrap'         : trial.suggest_categorical('bootstrap', [True, False]),\n",
    "        'min_weight_fraction_leaf': trial.suggest_float('min_weight_fraction_leaf', 0.0, 0.1),\n",
    "        'max_leaf_nodes'    : trial.suggest_int('max_leaf_nodes', 10, 1000),\n",
    "        \n",
    "        # Complexity control\n",
    "        'ccp_alpha'         : trial.suggest_float('ccp_alpha', 0.0, 0.1),\n",
    "    }\n",
    "\n",
    "    return search_space\n",
    "\n",
    "cv = TimeSeriesFold(\n",
    "         steps              = 21,\n",
    "         initial_train_size = len(data_train),\n",
    "         refit              = True,\n",
    "         fixed_train_size   = False,\n",
    "     )\n",
    "\n",
    "results, best_trial = bayesian_search_forecaster_multiseries(\n",
    "    forecaster       = forecaster,\n",
    "    series           = data.iloc[:train_size+val_size][list_uf],\n",
    "    exog             = None,\n",
    "    search_space     = search_space,\n",
    "    cv               = cv,\n",
    "    levels           = list_uf,\n",
    "    metric           = 'mean_absolute_error',\n",
    "    aggregate_metric = ['weighted_average', 'average', 'pooling'],\n",
    "    n_trials         = 5\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f00344a",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster.fit(\n",
    "    series = data.iloc[:train_size+val_size][list_uf],\n",
    "    exog= None,\n",
    "    store_in_sample_residuals=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de8630e",
   "metadata": {},
   "outputs": [],
   "source": [
    "col=\"2456\"\n",
    "set_dark_theme()\n",
    "plt.figure(figsize=(12, 4))\n",
    " \n",
    "data_train[col].plot( label='train')\n",
    "data_val[col].plot( label='validation')\n",
    "data_test[col].plot( label='test')\n",
    "preds[preds['level']==col]['pred'].plot(label='prediction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7321ba4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run RF_final_c1 at: http://127.0.0.1:5000/#/experiments/0/runs/46051fdf8d094ca68d2c7a0353e8f59e\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"Default\")\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "\n",
    "params = forecaster.regressor.get_params()\n",
    "params['lags'] = forecaster.lags\n",
    "params['window features'] = forecaster.window_features\n",
    "params['exogs'] = forecaster.exog_names_in_\n",
    "params['regressor'] = forecaster.regressor.__class__.__name__\n",
    "\n",
    "with mlflow.start_run(run_name='RF_final_c1') as run:\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.log_metrics({\"MMAE\" : mmae, \"RMSE\": mrmse, \"Native MAE\": np.mean(naive_mae),\"native RMSE\": np.mean(naive_rsme), \"Mean MAE\": np.mean(mean_mae), \"Mean RMSE\": np.mean(mean_rmse), \"Drift MAE\": np.mean(drift_mae), \"Drift RMSE\": np.mean(drift_rmse)})\n",
    "     # Save forecaster object as pickle\n",
    "    with open(\"RF_final_c1.pkl\", \"wb\") as f:\n",
    "        pickle.dump(forecaster, f)\n",
    "\n",
    "    # Log the pickle file as an artifact\n",
    "    mlflow.log_artifact(\"RF_final_c1.pkl\", artifact_path=\"pickle_folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "561d0428",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    return np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
    "\n",
    "def benchmark_mae(train_series, test_series):\n",
    "\n",
    "    train_series = pd.Series(train_series)\n",
    "    test_series = pd.Series(test_series)\n",
    "    \n",
    "    naive_preds = pd.Series(np.repeat(train_series.iloc[-1], len(test_series)), index=test_series.index)\n",
    "    \n",
    "    mean_pred = pd.Series(np.repeat(train_series.mean(), len(test_series)), index=test_series.index)\n",
    "    \n",
    "    n_train = len(train_series)\n",
    "    drift = (train_series.iloc[-1] - train_series.iloc[0]) / (n_train - 1)\n",
    "    drift_preds = []\n",
    "    for h in range(1, len(test_series) + 1):\n",
    "        drift_preds.append(train_series.iloc[-1] + h * drift)\n",
    "    drift_preds = pd.Series(drift_preds, index=test_series.index)\n",
    "    \n",
    "    results = {}\n",
    "    results['naive_mae'] = mean_absolute_error(test_series, naive_preds)\n",
    "    results['mean_mae'] = mean_absolute_error(test_series, mean_pred)\n",
    "    results['drift_mae'] = mean_absolute_error(test_series, drift_preds)\n",
    "    \n",
    "    results_rmse={}\n",
    "    results_rmse['naive_rmse'] = rmse(test_series, naive_preds)\n",
    "    results_rmse['mean_rmse'] = rmse(test_series, mean_pred)\n",
    "    results_rmse['drift_rmse'] = rmse(test_series, drift_preds)\n",
    "    \n",
    "    return results, results_rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfd87d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive RMSE: 3.80396680486475\n",
      "Mean RMSE: 4.542400892934671\n",
      "drift RMSE: 4.638216182484251\n",
      "======================\n",
      "Root Mean Squared Error for cluster 0: 2.71\n",
      "======================\n",
      "Naive MAE: 3.081632653061225\n",
      "Mean MAE: 3.8891682375761554\n",
      "Drift MAE: 3.8851569543480053\n",
      "======================\n",
      "Mean Absolute Error for cluster 0: 2.15\n"
     ]
    }
   ],
   "source": [
    "naive_mae=[]\n",
    "mean_mae=[]\n",
    "drift_mae=[]\n",
    "naive_rsme=[]\n",
    "mean_rmse=[]\n",
    "drift_rmse=[]\n",
    "for i in list_uf:\n",
    "    results, results_rmse = benchmark_mae(data.iloc[:train_size+val_size][i], data_test[i])\n",
    "    \n",
    "    naive_mae.append(results['naive_mae'])\n",
    "    mean_mae.append(results['mean_mae'])\n",
    "    drift_mae.append(results['drift_mae'])\n",
    "    naive_rsme.append(results_rmse['naive_rmse'])\n",
    "    mean_rmse.append(results_rmse['mean_rmse'])\n",
    "    drift_rmse.append(results_rmse['drift_rmse'])\n",
    "\n",
    "preds = forecaster.predict(steps=21)\n",
    "rmses=[]\n",
    "maes=[]\n",
    "for col in list_uf:\n",
    "    mae = mean_absolute_error(data_test[col], preds[preds['level']==col]['pred'])\n",
    "    maes.append(mae)\n",
    "    uf_rmse=rmse(data_test[col], preds[preds['level']==col]['pred'])\n",
    "    rmses.append(uf_rmse)\n",
    "\n",
    "mmae = np.mean(maes)\n",
    "mrmse = np.mean(rmses)\n",
    "\n",
    "print(\"Naive RMSE:\", np.mean(naive_rsme))\n",
    "print(\"Mean RMSE:\", np.mean(mean_rmse))\n",
    "print(\"drift RMSE:\", np.mean(drift_rmse))\n",
    "print(\"======================\")\n",
    "print(f\"Root Mean Squared Error for cluster 1: {mrmse:.2f}\")\n",
    "print(\"======================\")\n",
    "print(\"Naive MAE:\", np.mean(naive_mae))\n",
    "print(\"Mean MAE:\", np.mean(mean_mae))\n",
    "print(\"Drift MAE:\", np.mean(drift_mae))\n",
    "print(\"======================\")\n",
    "print(f\"Mean Absolute Error for cluster 1: {mmae:.2f}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
